---
layout: post
title: Mathematical Explanation<br/>
       Variational Auto-Encoder
intro: This article was created for those who would like to understand more about the mathematical reasoning behind a model such as VAE. For this purpose I am introducing a range of different concepts ...

start: This article was created for those who would like to understand more about the mathematical reasoning behind a model such as VAE. For this purpose I am introducing a range of different concepts in statistics that help understand the decision-making of this paper's authors. I sum- marized only the most relevant mathematical statements for this post of each topic. To make a VAE more comprehensive I emphasized 
  on the modeling of it and core concepts to computationally realize it. Aditionally, I used day-to-day examples and visualisations that help building an intuition. If you have any questions or suggestions regarding this topic feel free to contact me.

chapters: ["Introduction",
           "Modeling",
           "Bayesian inference",
           "The VAE architecture",
           "Variational inference",
           "The Evidence Lower Bound",
           "Monte Carlo Estimate",
           "Reparameterization Trick",
           "The Gradient",
           "Sources"]
---

<br/>

### Required knowledge

The following topics are necessary to understand this article:
- Basic probability theory
- Basic statistics
- Basic Deep Learning

I will recap some necessary core concepts from the following topics:
- MLE, MAP
- Bayesian inference
- Variational inference
- Monte Carlo Estimate

If you are keen to know more details about each topic I can suggest: 
- [Introduction to Mathematical Statistics by Hogg](https://minerva.it.manchester.ac.uk/~saralees/statbook2.pdf) 
- [Mathematical Statistics by van de Geer](https://www.stat.math.ethz.ch/~geer/mathstat.pdf) 
- [Monte Carlo Methods by Kroese](https://people.smp.uq.edu.au/DirkKroese/mccourse.pdf)

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

{% include chapter.html name="Introduction" %}

This article elaborates on relevant concepts and approaches mentioned in the paper [Auto-Encoding Variational Bayes by Diederik P. Kingma, Max Welling](https://arxiv.org/pdf/1312.6114.pdf).

<br/>

To understand the architecture of a VAE, a generator, and its mathematical model, we will need to determine first the goal of such a model type and its 
relationship to a discriminator. <br/>
With a discriminative model we want to make a prediction about an attribute based on various observations. Such a model tries to learn the mapping from that data 
to this attribute. (need to update the following) ***To do so it tries to find features of these observations that has the highest correlation with that attribute.***
But correlation is not causation. Imagine, when I was a little child, I always got upset when my mom bought apples that had some brown spots.
She always answered: "No, they are good! Those are just some injuries." 
Sure, as if apples are like humans and could have "injuries" - you are just trying to make these cheap apples palatable, was my response back then.
Indeed, my mom was right, injuries of the apples skin exposes its tissue to oxygen that turns polyphenol (a micronutrient in the apple) into melanin. 

Coming back to our problem, we could collect observations, like skin color of an apple and its surface structure and so on, to make a prediction whether an apple is rotten or not.
And, even though my mom was right, brown spots are usually a good indication since some infecting spores of fungi that occur in rotten apples create a brown coloration.
A discriminator would be able to find that correlation, like me as a child. 

<br/> Unfortunately, such a model will eliminate also apples that are healthy to consume but just had an injury.
Because of those instances, a model that can learn the causal relationship is of course more precise. 
To achieve that it would have to learn the generating process of rotten apples. 

If we abstract this case, we could say that an attribute like the level of decay is just another feature that describes an object.
From that perspective every object is a state of a collection of features or call it attributes if you like.

That would mean that an example of an apple is an expression of the following states:
- mainly red colored
- brown spots
- smooth skin
- *decomposed*
- etc.

<br/>

{% include highlights.html 
content_txt="Then a trained generator would tell us that the occurrence of all these features' states at the same time is very unrealistic.
In other words, a generator should /c/uncover how all the features that describe an object are jointly distributed/c/.
"%}

<br/>

Another important goal of training a generator is data completion. For instance, image resolution. For this purpose we need to transform the generator in a conditional generator.
It generates data depending on the state of some additional data, here a low-resolution image.

<br/>

{% include highlights.html 
content_txt="In summary, such a model should be used for **semi-supervised learning**, **data completion** and **generating realistic data**. And it does so by learning
the joint distribution of all features."%}

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>


{% include chapter.html name="Modeling" %}

<ins>*REMARK*:</ins> I usually use capital letters to denote random variables or vectors and *f* to denote probability density functions compared to *p* for 
probability mass functions. Since the authors of the VAE paper chose to use small letters for random vectors and *p* for both probability density and mass 
function I decided to stick with their notation.

<br/>

{% include highlights.html 
content_txt="Some of you may know that /c/finding a good data representation/c/, that includes extracting relevant features of the data, will increase the chances 
of training a good discriminator. Typical methods include the use of an auto-encoder or principal component analysis since such a representation is more expressive.
A new representation of a datapoint is called **latent feature vector**. The word, latent, stems from the fact that the space of latent features in a DL model for 
data representation is hidden from us. In my apple example from before we could say that the level of decay is also a latent feature.
" 
%}

<br/>

Let's first formulate that mathematically:

<br>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq1.png)

<br/>

{% include highlights.html 
content_txt="Next, we want to build a /c/neural network that parametrizes this joint distribution/c/. To achieve this I want to introduce the concept of a Bayesian Belief Network:
A **Bayesian Belief Network** is a directed acyclic graph where each node is a random variable and the edges (arcs) are the densities. It is useful to display the conditional
relationships between each random variables.
" 
%}

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq2.png)

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

{% include chapter.html name="Bayesian inference" %}

<br/>

{% include highlights.html 
content_txt="Since we do not know the pdf of the latent variables but might have some **prior knowledge** we can use Bayesian inference to /c/update prior distribution by posterior/c/." 
%}

<br>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq4.png)

<br/>
This principle will set up the architecture and mechanism of a VAE.
<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

{% include chapter.html name="The VAE architecture" %}

<br/>

{% include highlights.html 
content_txt="To obtain the **likelihood** a neural network learns its distribution during training while we need to assign another neural network with the task
to learn the distribution of the **posterior**. The latter type of neural network is called an inference model. For this purpose, the Variational Auto-Encoder
uses /c/an encoder to parametrize the posterior and a decoder to parametrize the likelihood/c/." 
%}

The following illustration captures this mechanism:

{% include image.html url="/images/2023-7-6-VAE/diag1.png" text="This diagram illustrates assignments of distributions." %}

<br/>
<br>

To understand the learning process for this model I will need to introduce you to the concept of a family of distributions:

<br>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq5.png)

<br>

{% include highlights.html 
content_txt="For unsupervised and semi-supervised learning the authors of this paper suggest to assume a **multivariate Gaussian**. Since a multivariate normal distribution has a **mean vector** and for this model suggested **diagonal covariance 
matrix** as its parameters the /c/inference model, here an encoder, has to define them to describe the posterior/c/. I will later on go further into detail.
"%}

<br>

{% include image.html url="/images/2023-7-6-VAE/vae_arch.png" text="An explanatory illustration that shows the model design." %}

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

{% include chapter.html name="Loss function" %}

<br/>
Both models learn the parameters via an update algorithm that searches a minimizer of a chosen objective, i.e. loss function. 
A typical objective would be Maximum A Posterior or Maximum Likelihood function to infer the best parameter for our model.

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq7.png)

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq8.png)

<br/>

Some update algorithms require sampling, like Monte Carlo processes, what makes them inefficient for large datasets.
A VAE uses a uniquely defined objective. In the next chapters I will introduce their proposed loss function.

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

{% include chapter.html name="Variational inference" %}

<br/>

{% include highlights.html 
content_txt="For Bayesian inference we have seen already that calculating the posterior requires the knowledge of /c/the evidence. Unfortunately, it is usually intractable/c/:
"%}

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq6.png)

<br/>


Either this integral has no closed-form solution due to the complexity of the data or the likelihood function is too complex due to nonlinear hidden layers.

<br/>

{% include highlights.html 
content_txt="
Instead, **variational inference** will bring us closer to the solution. It is /c/a method that approximates the posterior distribution through optimization/c/. The basic approach is to create a family of possible densities and with a distance measure to find the density from this family that is the closest to the one we want to approximate.
"%}

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/test9.png)

<br/>

Equation (2) is by itself not computable in our case because it involves calculating log(p(x)). The following calculation will show that:

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq10.png)

<br/>

{% include highlights.html 
content_txt="As we can see, /c/that optimization problem contains the log of the evidence which makes it not computable/c/."%}

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

{% include chapter.html name="The Evidence Lower Bound" %}

<br/>

Even though the Kullback-Leibner Divergence is not computable we can use it after applying some tweaks.

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq11.png)

<br/>

By adding the log(p(x)) term to the Kullback-Leibner Divergence we eliminate log(p(x)) from our objective.
With some further transformations we obtain an objective that we can use for our model.

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq12.png)

<br/>
With that new expression we only have to work with the prior, likelihood and posterior.
From the following property we can see the reason why it is called the evidence lower bound.

<br/>

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/eq13.png)

<br/>

Below you can find an animated example where p is a normal density function and q a gamma density function. 
The plot on top is the graph of the ELBO and below a plot of p and q with varying values for its parameters. 
The maximum of log(p) is zero for every distribution and since the ELBO is bounded from above by log(p) the ELBO is therefore
bounded by zero from above.

<br/> 

![_config.yml]({{ site.baseurl }}/images/2023-7-6-VAE/animation.gif)

<br/>

To get the maximizer of the ELBO via stochastic gradient decent we need to differentiate it w.r.t. the variational parameters φ and generative parameters θ.
That can be a bit tricky as we will see in the next chapters.

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br/>

<br/>

{% include chapter.html name="Monte Carlo Estimate" %}

sec 2.4.2

zitat:
the strategy is to obtain Monte Carlo estimates of the gradient of the variational objective and to use stochastic optimization to fit the variational parameter. (end)
there are two main strategies: black-box VI and reparameterization. 
zitat: But the gradient estimates of BBVI typically suffer from high variance, which can lead to slow convergence. (end)
hence, the second approach is recommended. zitat: They typically need only
one Monte Carlo sample to estimate a noisy gradient. 

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br>


{% include chapter.html name="Reparameterization Trick" %}

from script : VI where each data-case has a separate variational distribution, which is inefficient for large data-sets. The recognition model uses
one set of parameters to model the relation between input and latent variables and as such is called “amortized inference”.

<br>

zitat:
This approach reparameterizes the latent variable z in terms of a set of auxiliary random
variables whose distributions do not depend on the variational parameters. Reparameterization gradients exhibit lower variance than the other gradients estimate. They typically need only
one Monte Carlo sample to estimate a noisy gradient, which leads to fast algorithms. Further, for some
models, their variance can be bounded (Fan et al., 2015). However, reparameterization is not as generic
as bbvi. It is typically used with Gaussian variational distributions and does not easily generalize to
other common distributions, such as the gamma or beta, without using further approximations. (See
Knowles (2015) for an alternative approach to deal with the gamma distribution.)

<br>

zitat: 
Francisco J. R. Ruiz and David M. Blei developed the generalized reparameterization (g-rep) gradient, a new method to extend reparameterization to other variational distributions. 
The main idea is to define an invertible transformation of the
latent variables such that the distribution of the transformed variables is only weakly governed by the
variational parameters.
<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)


<br/>


{% include chapter.html name="The Gradient" %}

sec 2.3.

<br/>

![_config.yml]({{ site.baseurl }}/images/separator.png)

<br>

{% include chapter.html name="Sources" %}

- [Auto-Encoding Variational Bayes by Diederik P. Kingma, Max Welling](https://arxiv.org/pdf/1312.6114.pdf)
- [Variational Inference: A Review for Statisticians by David M. Blei](https://arxiv.org/pdf/1601.00670.pdf)
- [The Generalized Reparameterization Gradient by Francisco J. R. Ruiz and David M. Blei](https://proceedings.neurips.cc/paper_files/paper/2016/file/f718499c1c8cef6730f9fd03c8125cab-Paper.pdf)
- [Image Super-Resolution With Deep Variational Autoencoders by Darius Chira, Ilian Haralampiev](https://arxiv.org/pdf/2203.09445.pdf)
- [An Introduction to Variational Autoencoders by Diederik P. Kingma, Max Welling](https://arxiv.org/pdf/1906.02691.pdf)



![_config.yml]({{ site.baseurl }}/images/separator.png)

